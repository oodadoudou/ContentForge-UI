import os
import sys
import time
import json
import shutil
import traceback
from selenium import webdriver
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# --- è„šæœ¬æ ¸å¿ƒä»£ç  ---

def load_default_download_path():
    """
    ä»å…±äº«è®¾ç½®æ–‡ä»¶ä¸­è¯»å–é»˜è®¤å·¥ä½œç›®å½•ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›ç”¨æˆ·ä¸‹è½½æ–‡ä»¶å¤¹ã€‚
    """
    try:
        # å…¼å®¹æ‰“åŒ…åçš„ç¨‹åº (ä¾‹å¦‚ PyInstaller)
        if getattr(sys, 'frozen', False):
            project_root = os.path.dirname(sys.executable)
        # æ­£å¸¸è„šæœ¬æ‰§è¡Œæ—¶ï¼Œå‡å®šè„šæœ¬ä½äº 'scripts' ç­‰å­ç›®å½•ä¸­
        else:
            # ä¸Šæº¯ä¸¤çº§ç›®å½•æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•
            project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        
        settings_path = os.path.join(project_root, 'shared_assets', 'settings.json')
        
        if os.path.exists(settings_path):
            print(f"[ä¿¡æ¯] æ‰¾åˆ°é…ç½®æ–‡ä»¶: {settings_path}")
            with open(settings_path, 'r', encoding='utf-8') as f:
                settings = json.load(f)
            default_dir = settings.get("default_work_dir")
            
            # éªŒè¯è·¯å¾„æ˜¯å¦ä¸ºæœ‰æ•ˆç›®å½•
            if default_dir and os.path.isdir(default_dir):
                return default_dir
            elif default_dir:
                print(f"âš ï¸ è­¦å‘Š: é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„ '{default_dir}' æ— æ•ˆã€‚å°†ä½¿ç”¨åå¤‡è·¯å¾„ã€‚")

    except Exception as e:
        print(f"âš ï¸ è­¦å‘Š: è¯»å–é…ç½®æ–‡ä»¶æ—¶å‡ºé”™ ({e})ã€‚å°†ä½¿ç”¨åå¤‡è·¯å¾„ã€‚")

    # å¦‚æœä»¥ä¸Šä»»ä½•æ­¥éª¤å¤±è´¥ï¼Œåˆ™å›é€€åˆ°ç³»ç»Ÿé»˜è®¤çš„ä¸‹è½½æ–‡ä»¶å¤¹
    return os.path.join(os.path.expanduser("~"), "Downloads")


def setup_driver():
    """é…ç½®å¹¶è¿æ¥åˆ°å·²ç»æ‰“å¼€çš„ Chrome æµè§ˆå™¨å®ä¾‹"""
    print("æ­£åœ¨å°è¯•è¿æ¥åˆ°å·²å¯åŠ¨çš„ Chrome æµè§ˆå™¨...")
    print("è¯·ç¡®ä¿æ‚¨å·²æŒ‰ç…§è¯´æ˜ä½¿ç”¨ --remote-debugging-port=9222 å¯åŠ¨äº† Chromeã€‚")
    options = Options()
    options.add_experimental_option("debuggerAddress", "127.0.0.1:9222")
    try:
        driver = webdriver.Chrome(options=options)
        print("âœ… æˆåŠŸè¿æ¥åˆ°æµè§ˆå™¨ï¼")
        return driver
    except Exception as e:
        print(f"âŒ è¿æ¥æµè§ˆå™¨å¤±è´¥: {e}")
        print("è¯·ç¡®è®¤ï¼š")
        print("1. Chrome æµè§ˆå™¨æ˜¯å¦å·²é€šè¿‡å‘½ä»¤è¡Œå¯åŠ¨ï¼Œå¹¶å¸¦æœ‰ '--remote-debugging-port=9222' å‚æ•°ï¼Ÿ")
        print("2. æ˜¯å¦æ²¡æœ‰å…¶ä»– Chrome çª—å£ï¼ˆè¯·å®Œå…¨é€€å‡º Chrome åå†æŒ‰æŒ‡ä»¤å¯åŠ¨ï¼‰ï¼Ÿ")
        return None

def process_book(driver, start_url, download_path):
    """
    å¤„ç†å•æœ¬ä¹¦ç±çš„å®Œæ•´ä¸‹è½½æµç¨‹ï¼Œé‡‡ç”¨ä»ä¸»é¡µå¼€å§‹å¹¶æ»šåŠ¨åŠ è½½çš„ç­–ç•¥ã€‚
    """
    stats = {'skipped': 0, 'successful': 0, 'failed': 0, 'failed_items': []}
    
    try:
        # 1. ç¡®å®šä¹¦ç±çš„ä¸»é¡µURL
        is_chapter_url = "/episodes/" in start_url
        base_url = start_url.split('/episodes/')[0] if is_chapter_url else start_url.split('?')[0]
        base_url = base_url.rstrip('/')

        print(f"æ­£åœ¨è®¿é—®ä¹¦ç±ä¸»é¡µ: {base_url}")
        driver.get(base_url)
        wait = WebDriverWait(driver, 45)  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°45ç§’
        
        # 2. è·å–å°è¯´æ ‡é¢˜
        print("æ­£åœ¨ç­‰å¾…é¡µé¢åŠ è½½å¹¶è·å–å°è¯´æ ‡é¢˜...")
        
        # å°è¯•å¤šä¸ªå¯èƒ½çš„æ ‡é¢˜é€‰æ‹©å™¨
        title_selectors = [
            'p[class*="e1fhqjtj1"]',    # åŸå§‹é€‰æ‹©å™¨
            'h1[class*="title"]',       # å¤‡ç”¨é€‰æ‹©å™¨1
            'h1',                       # é€šç”¨h1é€‰æ‹©å™¨
            'h2[class*="title"]',       # å¤‡ç”¨é€‰æ‹©å™¨2
            '[class*="title"]',         # ä»»ä½•åŒ…å«titleçš„class
            '.title'                    # é€šç”¨titleç±»
        ]
        
        novel_title = None
        for selector in title_selectors:
            try:
                novel_title_element = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, selector)))
                novel_title = novel_title_element.text.strip().replace('/', '_').replace('\\', '_')
                if novel_title:  # ç¡®ä¿æ ‡é¢˜ä¸ä¸ºç©º
                    print(f"âœ… æ‰¾åˆ°å°è¯´æ ‡é¢˜ï¼Œä½¿ç”¨é€‰æ‹©å™¨: {selector}")
                    break
            except (TimeoutException, Exception):
                print(f"âš ï¸ é€‰æ‹©å™¨ {selector} æœªæ‰¾åˆ°æ ‡é¢˜ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
                continue
        
        if not novel_title:
            print("âš ï¸ è­¦å‘Š: æœªèƒ½è·å–å°è¯´æ ‡é¢˜ï¼Œä½¿ç”¨é»˜è®¤åç§°")
            novel_title = "æœªçŸ¥å°è¯´"
            
        print(f"ğŸ“˜ å°è¯´æ ‡é¢˜: {novel_title}")

        # 3. æ»šåŠ¨åˆ°åº•éƒ¨ä»¥åŠ è½½æ‰€æœ‰ç« èŠ‚
        print("æ­£åœ¨è·å–ç« èŠ‚åˆ—è¡¨ (æ»šåŠ¨åŠ è½½)...")
        
        # ä½¿ç”¨å¤šä¸ªå¯èƒ½çš„é€‰æ‹©å™¨æ¥æŸ¥æ‰¾ç« èŠ‚å®¹å™¨
        chapter_container_selectors = [
            'div[class*="eihlkz80"]',  # åŸå§‹é€‰æ‹©å™¨
            'div[class*="ese98wi3"]',  # å¤‡ç”¨é€‰æ‹©å™¨1
            'div[class*="episode"]',   # å¤‡ç”¨é€‰æ‹©å™¨2
            'div[data-testid*="episode"]',  # å¤‡ç”¨é€‰æ‹©å™¨3
            'div[class*="chapter"]',   # å¤‡ç”¨é€‰æ‹©å™¨4
            'div[class*="list"]'       # å¤‡ç”¨é€‰æ‹©å™¨5
        ]
        
        chapter_container_found = False
        for selector in chapter_container_selectors:
            try:
                wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, selector)))
                print(f"âœ… æ‰¾åˆ°ç« èŠ‚å®¹å™¨ï¼Œä½¿ç”¨é€‰æ‹©å™¨: {selector}")
                chapter_container_found = True
                break
            except TimeoutException:
                print(f"âš ï¸ é€‰æ‹©å™¨ {selector} æœªæ‰¾åˆ°å…ƒç´ ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
                continue
        
        if not chapter_container_found:
            print("âŒ è­¦å‘Š: æœªèƒ½æ‰¾åˆ°ç« èŠ‚å®¹å™¨ï¼Œä½†ç»§ç»­å°è¯•æ»šåŠ¨åŠ è½½...")
        
        # æ»šåŠ¨åŠ è½½ç­–ç•¥ï¼Œå¢åŠ å°è¯•æ¬¡æ•°é™åˆ¶
        last_height = driver.execute_script("return document.body.scrollHeight")
        scroll_attempts = 0
        max_scroll_attempts = 10
        
        while scroll_attempts < max_scroll_attempts:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(3)  # å¢åŠ ç­‰å¾…æ—¶é—´
            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                print("âœ… å·²æ»šåŠ¨åˆ°åº•éƒ¨ï¼ŒåŠ è½½å®Œæˆã€‚")
                break
            last_height = new_height
            scroll_attempts += 1
            print(f"  æ»šåŠ¨ä¸­... ({scroll_attempts}/{max_scroll_attempts})")
        
        if scroll_attempts >= max_scroll_attempts:
            print("âš ï¸ è¾¾åˆ°æœ€å¤§æ»šåŠ¨å°è¯•æ¬¡æ•°ï¼Œåœæ­¢æ»šåŠ¨ã€‚")
        
        # 4. è·å–æ‰€æœ‰ç« èŠ‚é“¾æ¥
        # å°è¯•å¤šä¸ªå¯èƒ½çš„ç« èŠ‚åˆ—è¡¨å®¹å™¨é€‰æ‹©å™¨
        chapter_list_selectors = [
            'div[class*="ese98wi3"]',  # åŸå§‹é€‰æ‹©å™¨
            'div[class*="eihlkz80"]',  # å¤‡ç”¨é€‰æ‹©å™¨1
            'div[class*="episode"]',   # å¤‡ç”¨é€‰æ‹©å™¨2
            'div[class*="chapter"]',   # å¤‡ç”¨é€‰æ‹©å™¨3
            'div[class*="list"]',      # å¤‡ç”¨é€‰æ‹©å™¨4
            'main',                    # é€šç”¨å®¹å™¨é€‰æ‹©å™¨
            'body'                     # æœ€åçš„å…œåº•é€‰æ‹©å™¨
        ]
        
        chapter_list_container = None
        for selector in chapter_list_selectors:
            try:
                chapter_list_container = driver.find_element(By.CSS_SELECTOR, selector)
                print(f"âœ… æ‰¾åˆ°ç« èŠ‚åˆ—è¡¨å®¹å™¨ï¼Œä½¿ç”¨é€‰æ‹©å™¨: {selector}")
                break
            except Exception:
                print(f"âš ï¸ é€‰æ‹©å™¨ {selector} æœªæ‰¾åˆ°ç« èŠ‚åˆ—è¡¨å®¹å™¨ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
                continue
        
        if chapter_list_container is None:
            print("âŒ é”™è¯¯: æœªèƒ½æ‰¾åˆ°ä»»ä½•ç« èŠ‚åˆ—è¡¨å®¹å™¨ã€‚")
            return None, None, stats
        
        # å°è¯•å¤šä¸ªå¯èƒ½çš„ç« èŠ‚é“¾æ¥é€‰æ‹©å™¨
        chapter_link_selectors = [
            'a[href*="/episodes/"]',     # åŸå§‹é€‰æ‹©å™¨
            'a[href*="episode"]',        # å¤‡ç”¨é€‰æ‹©å™¨1
            'a[href*="chapter"]',        # å¤‡ç”¨é€‰æ‹©å™¨2
            'a[class*="episode"]',       # å¤‡ç”¨é€‰æ‹©å™¨3
            'a[class*="chapter"]'        # å¤‡ç”¨é€‰æ‹©å™¨4
        ]
        
        full_url_list = []
        for selector in chapter_link_selectors:
            try:
                chapter_links_elements = chapter_list_container.find_elements(By.CSS_SELECTOR, selector)
                if chapter_links_elements:
                    urls = [elem.get_attribute('href') for elem in chapter_links_elements if elem.get_attribute('href')]
                    full_url_list = sorted(list(set(urls)))
                    print(f"âœ… æ‰¾åˆ°ç« èŠ‚é“¾æ¥ï¼Œä½¿ç”¨é€‰æ‹©å™¨: {selector}")
                    break
            except Exception:
                print(f"âš ï¸ é€‰æ‹©å™¨ {selector} æœªæ‰¾åˆ°ç« èŠ‚é“¾æ¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
                continue

        if not full_url_list:
            print("âŒ é”™è¯¯: æœªèƒ½æ‰¾åˆ°ä»»ä½•ç« èŠ‚é“¾æ¥ã€‚")
            return None, None, stats
            
        print(f"å…±æ‰¾åˆ° {len(full_url_list)} ä¸ªç« èŠ‚ã€‚")

        # 5. ç¡®å®šä¸‹è½½èµ·ç‚¹
        start_index = 0
        if is_chapter_url:
            try:
                clean_start_url = start_url.split('?')[0].rstrip('/')
                clean_full_url_list = [url.split('?')[0].rstrip('/') for url in full_url_list]
                start_index = clean_full_url_list.index(clean_start_url)
                print(f"âœ… æ‰¾åˆ°ä¸‹è½½èµ·ç‚¹ï¼Œå°†ä»ç¬¬ {start_index + 1} ç« å¼€å§‹å¤„ç†ã€‚")
            except ValueError:
                print(f"âš ï¸ è­¦å‘Š: æ‚¨è¾“å…¥çš„ç« èŠ‚URL {start_url} æœªåœ¨æœ€ç»ˆçš„ç›®å½•åˆ—è¡¨ä¸­æ‰¾åˆ°ã€‚å°†ä»ç¬¬ä¸€ç« å¼€å§‹å¤„ç†ã€‚")
        
        # åˆ›å»ºä»¥å°è¯´åå‘½åçš„ä¸»ç›®å½•
        book_dir = os.path.join(download_path, novel_title)
        os.makedirs(book_dir, exist_ok=True)
        print(f"æ‰€æœ‰æ–‡ä»¶å°†ä¿å­˜åœ¨: {book_dir}")
        
        # 6. å¾ªç¯ä¸‹è½½æ¯ä¸ªç« èŠ‚ï¼Œå¹¶åŠ å…¥é‡è¯•é€»è¾‘
        for i, url in enumerate(full_url_list[start_index:], start=start_index):
            chapter_number = i + 1
            print(f"\n--- æ­£åœ¨å¤„ç†ã€Š{novel_title}ã€‹- ç¬¬ {chapter_number} / {len(full_url_list)} ç«  ---")
            
            chapter_prefix = f"{str(chapter_number).zfill(4)}_"
            
            # åœ¨æ–°çš„ book_dir ä¸­æ£€æŸ¥æ–‡ä»¶
            # æ£€æŸ¥ä¸»ç›®å½•å’Œ chapters å­ç›®å½•ä¸­æ˜¯å¦å·²å­˜åœ¨
            chapters_subdir = os.path.join(book_dir, "chapters")
            existing_in_main = [f for f in os.listdir(book_dir) if f.startswith(chapter_prefix) and os.path.isfile(os.path.join(book_dir, f))]
            existing_in_sub = []
            if os.path.exists(chapters_subdir):
                existing_in_sub = [f for f in os.listdir(chapters_subdir) if f.startswith(chapter_prefix)]

            if existing_in_main or existing_in_sub:
                existing_file_name = (existing_in_main + existing_in_sub)[0]
                print(f"âœ… æ£€æµ‹åˆ°æ–‡ä»¶ '{existing_file_name}'ï¼Œæœ¬ç« å·²ä¸‹è½½ï¼Œå°†è·³è¿‡ã€‚")
                stats['skipped'] += 1
                continue

            retries = 0
            MAX_RETRIES = 3
            download_successful = False
            
            while retries < MAX_RETRIES and not download_successful:
                try:
                    if retries > 0:
                        print(f"  - ç¬¬ {retries} æ¬¡é‡è¯•... URL: {url}")
                    else:
                        print(f"  - URL: {url}")
                        
                    driver.get(url)

                    # å°è¯•å¤šä¸ªå¯èƒ½çš„ç« èŠ‚æ ‡é¢˜é€‰æ‹©å™¨
                    chapter_title_selectors = [
                        'span[class*="e14fx9ai3"]',  # åŸå§‹é€‰æ‹©å™¨
                        'h1[class*="title"]',        # å¤‡ç”¨é€‰æ‹©å™¨1
                        'h1',                        # é€šç”¨h1é€‰æ‹©å™¨
                        'h2',                        # å¤‡ç”¨h2é€‰æ‹©å™¨
                        '[class*="title"]'           # ä»»ä½•åŒ…å«titleçš„class
                    ]
                    
                    chapter_title = None
                    for selector in chapter_title_selectors:
                        try:
                            chapter_title_element = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, selector)))
                            chapter_title = chapter_title_element.text.strip()
                            if chapter_title:  # ç¡®ä¿æ ‡é¢˜ä¸ä¸ºç©º
                                break
                        except (TimeoutException, Exception):
                            continue
                    
                    if not chapter_title:
                        chapter_title = f"ç¬¬{chapter_number}ç« "
                        print(f"  âš ï¸ æ— æ³•è·å–ç« èŠ‚æ ‡é¢˜ï¼Œä½¿ç”¨é»˜è®¤: {chapter_title}")
                    
                    # å°è¯•å¤šä¸ªå¯èƒ½çš„å†…å®¹é€‰æ‹©å™¨
                    content_selectors = [
                        '.tiptap.ProseMirror',       # åŸå§‹é€‰æ‹©å™¨
                        '.content',                  # é€šç”¨å†…å®¹é€‰æ‹©å™¨
                        '[class*="content"]',        # ä»»ä½•åŒ…å«contentçš„class
                        '.ProseMirror',              # ProseMirrorç¼–è¾‘å™¨
                        '[class*="text"]',           # ä»»ä½•åŒ…å«textçš„class
                        'article'                    # articleæ ‡ç­¾
                    ]
                    
                    content = None
                    for selector in content_selectors:
                        try:
                            content_container = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, selector)))
                            content_elements = content_container.find_elements(By.CSS_SELECTOR, 'p')
                            if content_elements:
                                content = "\n\n".join([p.text for p in content_elements if p.text.strip()])
                                if content.strip():  # ç¡®ä¿å†…å®¹ä¸ä¸ºç©º
                                    break
                        except (TimeoutException, Exception):
                            continue
                    
                    if not content or not content.strip():
                        raise ValueError("è·å–åˆ°çš„å†…å®¹ä¸ºç©ºï¼Œå¯èƒ½é¡µé¢ç»“æ„å·²å˜åŒ–ã€‚")

                    sanitized_title = chapter_title.replace('/', '_').replace('\\', '_').replace(':', 'ï¼š')
                    file_name = f"{chapter_prefix}{sanitized_title}.txt"
                    file_path = os.path.join(book_dir, file_name)
                    
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(f"{chapter_title}\n\n")
                        f.write(content)
                    
                    print(f"  âœ… å·²ä¿å­˜: {file_name}")
                    stats['successful'] += 1
                    download_successful = True

                except Exception as e:
                    retries += 1
                    error_msg = str(e)
                    print(f"  - æŠ“å–æœ¬ç« æ—¶å‡ºé”™ (å°è¯• {retries}/{MAX_RETRIES}): {error_msg}")
                    
                    # å¦‚æœæ˜¯TimeoutExceptionï¼Œæä¾›æ›´è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
                    if "TimeoutException" in error_msg or "timeout" in error_msg.lower():
                        print(f"  - è¶…æ—¶é”™è¯¯ï¼Œå¯èƒ½æ˜¯é¡µé¢åŠ è½½è¿‡æ…¢æˆ–å…ƒç´ é€‰æ‹©å™¨å·²å˜åŒ–")
                        print(f"  - å½“å‰é¡µé¢URL: {driver.current_url}")
                        try:
                            page_source_preview = driver.page_source[:500]
                            print(f"  - é¡µé¢æºç é¢„è§ˆ: {page_source_preview}...")
                        except:
                            print("  - æ— æ³•è·å–é¡µé¢æºç é¢„è§ˆ")
                    
                    if retries < MAX_RETRIES:
                        time.sleep(5)  # å¢åŠ é‡è¯•é—´éš”
                    else:
                        print(f"  âŒ æŠ“å–æœ¬ç« å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ã€‚")
                        stats['failed'] += 1
                        stats['failed_items'].append({'url': url, 'error': error_msg})

            time.sleep(2)
            
        return novel_title, book_dir, stats

    except Exception as e:
        print(f"âŒ åœ¨å¤„ç†ä¹¦ç± {start_url} æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        traceback.print_exc()
        return None, None, stats

def merge_chapters(novel_title, book_dir):
    """å°†æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰TXTæ–‡ä»¶æŒ‰é¡ºåºåˆå¹¶ï¼Œç„¶åå°†åˆ†å·ç§»åŠ¨åˆ°å­ç›®å½•ã€‚å°äº3KBçš„æ–‡ä»¶å°†è¢«è·³è¿‡åˆå¹¶ã€‚"""
    merged_filename = os.path.join(book_dir, f"{novel_title}.txt")
    print(f"\nğŸ”„ å¼€å§‹åˆå¹¶æ‰€æœ‰ç« èŠ‚åˆ°ä¸€ä¸ªæ–‡ä»¶: {merged_filename}")
    
    try:
        if not os.path.exists(book_dir):
            print(f"âš ï¸ è­¦å‘Š: ç›®å½• {book_dir} ä¸å­˜åœ¨ï¼Œæ— æ³•åˆå¹¶ã€‚")
            return
        
        # è·å–æ‰€æœ‰åŸå§‹çš„ txt æ–‡ä»¶
        all_txt_files = sorted([f for f in os.listdir(book_dir) if f.endswith('.txt') and os.path.isfile(os.path.join(book_dir, f))])

        if not all_txt_files:
            print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°å¯ä¾›åˆå¹¶çš„ç« èŠ‚æ–‡ä»¶ã€‚")
            return

        # ç­›é€‰å‡ºå¤§äºç­‰äº3KBçš„æ–‡ä»¶ç”¨äºåˆå¹¶
        files_to_merge = []
        for filename in all_txt_files:
            file_path = os.path.join(book_dir, filename)
            # ä¿®æ”¹ï¼šå°†åˆ¤æ–­æ¡ä»¶ä» 800 å­—èŠ‚æ”¹ä¸º 3 KB (3 * 1024 bytes)
            if os.path.getsize(file_path) < 3 * 1024:
                print(f"  - [è·³è¿‡åˆå¹¶] æ–‡ä»¶ '{filename}' å°äº 3 KBï¼Œè§†ä¸ºéæ­£æ–‡å†…å®¹ã€‚")
            else:
                files_to_merge.append(filename)

        if not files_to_merge:
            print("âš ï¸ è­¦å‘Š: ç­›é€‰åæ²¡æœ‰ç¬¦åˆå¤§å°è¦æ±‚çš„ç« èŠ‚æ–‡ä»¶å¯ä¾›åˆå¹¶ã€‚")
        else:
            with open(merged_filename, 'w', encoding='utf-8') as outfile:
                for i, filename in enumerate(files_to_merge):
                    file_path = os.path.join(book_dir, filename)
                    with open(file_path, 'r', encoding='utf-8') as infile:
                        outfile.write(infile.read())
                    
                    if i < len(files_to_merge) - 1:
                        outfile.write("\n\n\n==========\n\n\n")
            
            print(f"âœ… åˆå¹¶å®Œæˆï¼å°è¯´å·²ä¿å­˜è‡³: {os.path.abspath(merged_filename)}")
        
        # å°†æ‰€æœ‰åŸå§‹çš„ txt æ–‡ä»¶ç§»åŠ¨åˆ° chapters å­ç›®å½•
        chapters_subdir = os.path.join(book_dir, "chapters")
        os.makedirs(chapters_subdir, exist_ok=True)
        
        for filename in all_txt_files:
            src_path = os.path.join(book_dir, filename)
            dest_path = os.path.join(chapters_subdir, filename)
            if os.path.exists(src_path) and src_path != merged_filename:
                shutil.move(src_path, dest_path)

        print(f"ğŸ“‚ ç« èŠ‚åˆ†å·æ–‡ä»¶å·²ç§»åŠ¨åˆ°å­ç›®å½•: {os.path.abspath(chapters_subdir)}")
        
    except Exception as e:
        print(f"âŒ åˆå¹¶æˆ–ç§»åŠ¨æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")

def print_book_report(stats, novel_title):
    """æ‰“å°å•æœ¬ä¹¦ç±çš„æ‰§è¡ŒæŠ¥å‘Š"""
    print("\n" + "="*40)
    print(f"ğŸ“‹ å•æœ¬æŠ¥å‘Š: {novel_title or 'æœªçŸ¥ä¹¦ç±'}")
    print("="*40)
    print(f"âœ… æˆåŠŸä¸‹è½½: {stats['successful']} ç« ")
    print(f"â­ï¸ è·³è¿‡ä¸‹è½½: {stats['skipped']} ç«  (å·²å­˜åœ¨)")
    print(f"âŒ ä¸‹è½½å¤±è´¥: {stats['failed']} ç« ")
    
    if stats['failed_items']:
        print("\n--- å¤±è´¥é¡¹ç›®è¯¦æƒ… ---")
        for item in stats['failed_items']:
            print(f"  - URL: {item['url']}")
    print("="*40)

def print_total_report(all_book_stats):
    """æ‰“å°æ‰€æœ‰ä»»åŠ¡çš„æ€»æŠ¥å‘Š"""
    total_stats = {
        'books_processed': len(all_book_stats),
        'books_completed_successfully': 0,
        'books_with_failures': 0,
        'total_successful': 0,
        'total_skipped': 0,
        'total_failed': 0,
    }

    for stats in all_book_stats:
        total_stats['total_successful'] += stats['successful']
        total_stats['total_skipped'] += stats['skipped']
        total_stats['total_failed'] += stats['failed']
        if stats['failed'] > 0:
            total_stats['books_with_failures'] += 1
        else:
            total_stats['books_completed_successfully'] += 1

    print("\n" + "#"*50)
    print("ğŸ“Š æ‰€æœ‰ä»»åŠ¡æ€»æŠ¥å‘Š")
    print("#"*50)
    print(f"å¤„ç†ä¹¦ç±æ€»æ•°: {total_stats['books_processed']}")
    print(f"âœ… å®Œç¾å®Œæˆçš„ä¹¦ç±: {total_stats['books_completed_successfully']}")
    print(f"âš ï¸ éƒ¨åˆ†å¤±è´¥çš„ä¹¦ç±: {total_stats['books_with_failures']}")
    print("-" * 20)
    print(f"æ€»è®¡æˆåŠŸä¸‹è½½ç« èŠ‚: {total_stats['total_successful']}")
    print(f"æ€»è®¡è·³è¿‡ç« èŠ‚: {total_stats['total_skipped']}")
    print(f"æ€»è®¡å¤±è´¥ç« èŠ‚: {total_stats['total_failed']}")
    print("#"*50)


if __name__ == "__main__":
    default_download_path = load_default_download_path()
    print(f"[ä¿¡æ¯] å½“å‰ä¸‹è½½è·¯å¾„è®¾ç½®ä¸º: {default_download_path}")
    
    print("\nè¯·è¾“å…¥ä¸€ä¸ªæˆ–å¤šä¸ªDirittoå°è¯´URL (å¯åˆ†å¤šè¡Œç²˜è´´, è¾“å…¥å®ŒæˆåæŒ‰ä¸¤æ¬¡å›è½¦ç»“æŸ):")
    lines = []
    while True:
        try:
            line = input()
            if not line:
                break
            lines.append(line)
        except EOFError:
            break
    
    urls_input = " ".join(lines)
    url_list = [url for url in urls_input.split() if url.startswith("http")]

    if not url_list:
        print("âŒ é”™è¯¯: æœªè¾“å…¥æœ‰æ•ˆçš„URLã€‚")
    else:
        if not os.path.exists(default_download_path):
            os.makedirs(default_download_path)
            print(f"å·²åˆ›å»ºä¸‹è½½ç›®å½•: {default_download_path}")
        
        driver = setup_driver()
        if driver:
            all_book_stats = []
            try:
                # --- é¡ºåºå¤„ç†ä¹¦ç± ---
                for i, novel_url in enumerate(url_list):
                    print("\n" + "#"*60)
                    print(f"# å¼€å§‹å¤„ç†ç¬¬ {i + 1} / {len(url_list)} æœ¬ä¹¦: {novel_url}")
                    print("#"*60 + "\n")

                    novel_title, book_dir, book_stats = process_book(driver, novel_url, default_download_path)
                    
                    if book_stats:
                        all_book_stats.append(book_stats)
                        print_book_report(book_stats, novel_title)

                    if novel_title and book_dir:
                        if book_stats and book_stats['failed'] > 0:
                            print(f"\nâš ï¸ã€Š{novel_title}ã€‹æ£€æµ‹åˆ°ä¸‹è½½å¤±è´¥çš„é¡¹ç›®ï¼Œå·²è·³è¿‡æ–‡ä»¶åˆå¹¶ã€‚")
                            print(f"æºæ–‡ä»¶ä¿ç•™åœ¨ç›®å½•ä¸­: {os.path.abspath(book_dir)}")
                        else:
                            merge_chapters(novel_title, book_dir)
            finally:
                if all_book_stats:
                    print_total_report(all_book_stats)
                print("\næ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ã€‚æ‚¨å¯ä»¥æ‰‹åŠ¨å…³é—­æµè§ˆå™¨ã€‚")
